{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Translate_MNLI.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3q31naT15f-"
      },
      "source": [
        "!pip install torchtext==0.8.0\n",
        "!pip install torch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2\n",
        "!pip install ftfy --quiet\n",
        "!pip install transformers --quiet \n",
        "!pip install sentencepiece --quiet\n",
        "! wget https://dl.fbaipublicfiles.com/glue/data/MNLI.zip\n",
        "! unzip /content/MNLI.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xZ_hZ7H5toj"
      },
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "from tqdm.notebook import tqdm\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from ftfy import fix_encoding\n",
        "import ftfy\n",
        "import re\n",
        "\n",
        "import torch\n",
        "if torch.cuda.is_available(): \n",
        "   dev = \"cuda:0\"\n",
        "else: \n",
        "   dev = \"cpu\" \n",
        "print(dev, torch.cuda.get_device_name(0))\n",
        "device = torch.device(dev)\n",
        "\n",
        "# Model\n",
        "model_name = 'Helsinki-NLP/opus-mt-en-ROMANCE'\n",
        "marian_tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "marian_model = MarianMTModel.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tth7X5Ou76-W"
      },
      "source": [
        "nlp = English()\n",
        "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
        "def chunkstring_spacy(text):\n",
        "    \"\"\"\n",
        "    Segment text and prepare to translation\n",
        "\n",
        "    Args:\n",
        "      text: Sentence to be translated\n",
        "      \n",
        "    Returns:\n",
        "      Segmented text.\n",
        "    \"\"\"\n",
        "    chunck_sentences = []\n",
        "    doc = nlp(str(text))\n",
        "    for sent in doc.sents:\n",
        "        chunck_sentences.append('>>pt_br<<' + ' ' + sent.text)\n",
        "        \n",
        "    return chunck_sentences\n",
        "\n",
        "def translate(aux_sent):\n",
        "    \"\"\"\n",
        "    Translate text\n",
        "\n",
        "    Args:\n",
        "      aux_sent: Sentence to be translated\n",
        "      \n",
        "    Returns:\n",
        "      Translated text.\n",
        "    \"\"\"\n",
        "    max_length = 512\n",
        "    num_beams = 1\n",
        "\n",
        "    sentence = chunkstring_spacy(aux_sent)\n",
        "\n",
        "    #Move o modelo para a GPU\n",
        "    marian_model.to(device)\n",
        "    marian_model.eval()\n",
        "\n",
        "    tokenized_text = marian_tokenizer.prepare_seq2seq_batch(sentence, max_length=max_length, return_tensors='pt')\n",
        "                        \n",
        "    translated = marian_model.generate(input_ids=tokenized_text['input_ids'].to(device), \n",
        "                                        max_length=max_length, \n",
        "                                        num_beams=num_beams, \n",
        "                                        early_stopping=True, \n",
        "                                        do_sample=False)\n",
        "                        \n",
        "    tgt_text = [fix_encoding(marian_tokenizer.decode(t, skip_special_tokens=True)) for t in translated]\n",
        "    return ' '.join(tgt_text)\n",
        "\n",
        "def MNLI_translate(input):\n",
        "    \"\"\"\n",
        "    Translate MNLI train set to Portuguese\n",
        "    Args:\n",
        "      input: Dataset to be translated\n",
        "\n",
        "    Returns:\n",
        "      CSV containing the translated dataset.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv('{}'.format(input), sep='\\t', header=0, error_bad_lines=False)\n",
        "    print('Translating MNLI ...')\n",
        "    sent_1 = df['sentence1'].tolist()\n",
        "    sent_2 = df['sentence2'].tolist()\n",
        "\n",
        "    index = df['index'].tolist()\n",
        "    prompt = df['promptID'].tolist()\n",
        "    pair = df['pairID'].tolist()\n",
        "    genre = df['genre'].tolist()\n",
        "    binary1 = df['sentence1_binary_parse'].tolist()\n",
        "    binary2 = df['sentence2_binary_parse'].tolist()\n",
        "    parse1 = df['sentence1_parse'].tolist()\n",
        "    parse2 = df['sentence2_parse'].tolist()\n",
        "    label = df['label1'].tolist()\n",
        "    gold_label = df['gold_label'].tolist()\n",
        "\n",
        "    list_tuples = []\n",
        "   \n",
        "    for sent1, sent2, i, p, p2, g, b, b2, p3, p4, l, gold in zip(tqdm(sent_1), sent_2, index, prompt, pair, genre, binary1, binary2, parse1, parse2, label, gold_label): \n",
        "        if not str(sent1).endswith('.'):\n",
        "            sent1 = sent1+'.'\n",
        "        sent = str(sent1) + ' ' + str(sent2)\n",
        "        saida_sent = translate(sent)\n",
        "\n",
        "        try:\n",
        "            new_sent1 = saida_sent.split('. ')[0]\n",
        "            new_sent2 = saida_sent.split('. ')[1]\n",
        "\n",
        "            tuples = (i, p, p2, g, b, b2, p3, p4, new_sent1, new_sent2, l, gold)\n",
        "            list_tuples.append(tuples)\n",
        "\n",
        "        except:  \n",
        "            pass      \n",
        "      \n",
        "\n",
        "    df_final = pd.DataFrame(list_tuples, columns = df.columns)\n",
        "\n",
        "    df_final.to_csv('/content/MNLI-translated.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8-83M8SuiAm"
      },
      "source": [
        "### Run code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36K_oxwa_pr5"
      },
      "source": [
        "input = '/content/MNLI/train.tsv'\n",
        "MNLI_translate(input)"
      ],
      "execution_count": 5,
      "outputs": []
    }
  ]
}